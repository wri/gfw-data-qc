{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52fc438",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from typing import Any, Dict, List, Sequence, Set, Tuple\n",
    "\n",
    "def compose_query_string(\n",
    "    base_column: str,\n",
    "    additional_columns: List[str],\n",
    "    intersections: List[str],\n",
    "    version: str = \"latest\",\n",
    "    dataset: str = \"gadm__tcl__iso_change\",\n",
    "    api_uri: str = \"https://staging-data-api.globalforestwatch.org\"\n",
    ") -> str:\n",
    "    base_uri = f\"{api_uri}/dataset/{dataset}/{version}/query/json?sql=\"\n",
    "\n",
    "    base_query_sql: str = (\n",
    "        \"select \"\n",
    "        + \", \".join([\n",
    "            f\"sum({base_column}) as {base_column}\",\n",
    "            *additional_columns\n",
    "        ])\n",
    "        + \" from data\"\n",
    "    )\n",
    "\n",
    "    intersections_sql = \"where \" + \" and \".join(i for i in intersections) if intersections else \"\"\n",
    "\n",
    "    group_by_sql =  \"group by \" + \", \".join(c for c in additional_columns) if additional_columns else \"\"\n",
    "\n",
    "#     order_by_sql =  \"order by \" + \", \".join(c for c in additional_columns) if additional_columns else \"\"\n",
    "\n",
    "    query_sql = \" \".join([base_query_sql, intersections_sql, group_by_sql])  # , order_by_sql])\n",
    "\n",
    "    return base_uri + query_sql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f480fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "SQLQueryArgs = namedtuple(\"SQLQueryArgs\", [\"base_column\", \"additional_columns\", \"intersections\"])\n",
    "\n",
    "\n",
    "# Base columns (i.e. columns to be summed across rows)\n",
    "emissions = '\"gfw_full_extent_gross_emissions__Mg_CO2e\"'    # The quotes are needed to preserve case!\n",
    "# removals  = '\"gfw_full_extent_gross_removals__Mg_CO2\"'    # The quotes are needed to preserve case!\n",
    "# net_flux  = '\"gfw_full_extent_net_flux__Mg_CO2e\"'         # The quotes are needed to preserve case!\n",
    "TCL = \"umd_tree_cover_loss__ha\"\n",
    "TCLF = \"umd_tree_cover_loss_from_fires__ha\"\n",
    "\n",
    "# More column names\n",
    "drivers__type  = \"tsc_tree_cover_loss_drivers__type\"\n",
    "logging_type   = \"gfw_planted_forests__type\"\n",
    "TCD_2k__thresh = \"umd_tree_cover_density_2000__threshold\"\n",
    "TCL__year      = \"umd_tree_cover_loss__year\"\n",
    "WDPA__cat      = \"wdpa_protected_areas__iucn_cat\"\n",
    "\n",
    "# Intersections (boolean SQL snippets)\n",
    "has_drivers_type = f\"{drivers__type} IS NOT NULL\"\n",
    "has_logging_type = f\"{logging_type} IS NOT NULL\"\n",
    "has_WDPA_cat     = f\"{WDPA__cat} IS NOT NULL\"\n",
    "\n",
    "is_AZE            = \"is__birdlife_alliance_for_zero_extinction_site = true\"\n",
    "is_IFL_2k         = \"is__ifl_intact_forest_landscapes_2000 = true\"\n",
    "is_indigenous     = \"is__landmark_indigenous_and_community_lands = true\"\n",
    "is_KBA            = \"is__birdlife_key_biodiversity_areas = true\"\n",
    "is_mangroves_1996 = \"is__gmw_global_mangrove_extent_1996 = true\"\n",
    "is_mining         = \"is__gfw_mining_concessions = true\"\n",
    "is_oil_palm       = \"is__gfw_oil_palm = true\"\n",
    "is_plantation     = \"is__gfw_managed_forests = true\"\n",
    "is_primary        = \"is__umd_regional_primary_forest_2001 = true\"\n",
    "is_wood_fiber     = \"is__gfw_wood_fiber = true\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4564b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "versions = [\"v20221104\", \"v20230412\"]\n",
    "\n",
    "# Setup the GHG comparisons\n",
    "columns_of_interest = [\n",
    "    \"iso\",\n",
    "    TCD_2k__thresh,\n",
    "    TCL__year,\n",
    "    drivers__type,\n",
    "    logging_type,\n",
    "    WDPA__cat\n",
    "]\n",
    "\n",
    "GHG_intersections = [\n",
    "    is_AZE,\n",
    "    is_IFL_2k,\n",
    "    is_indigenous,\n",
    "    is_KBA,\n",
    "    is_mangroves_1996,\n",
    "    is_mining,\n",
    "    is_oil_palm,\n",
    "    is_plantation,\n",
    "    is_primary,\n",
    "    is_wood_fiber\n",
    "]\n",
    "\n",
    "# base_column, [additional_columns], [intersections]\n",
    "GHG_query_args: List[SQLQueryArgs] = [\n",
    "    SQLQueryArgs(emissions, columns_of_interest, []),\n",
    "    *[\n",
    "        SQLQueryArgs(emissions, columns_of_interest, [intersection])\n",
    "        for intersection in GHG_intersections\n",
    "    ]\n",
    "]\n",
    "\n",
    "# GHG_query_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fe3747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the TCL/TCLF comparisons\n",
    "\n",
    "TCL_intersections = [\n",
    "    has_drivers_type,\n",
    "    is_IFL_2k,\n",
    "    is_primary,\n",
    "    has_WDPA_cat\n",
    "]\n",
    "\n",
    "TCLF_intersections = [\n",
    "    is_AZE,\n",
    "    is_indigenous,\n",
    "    is_KBA,\n",
    "    has_logging_type,\n",
    "    is_mining,\n",
    "    is_oil_palm,\n",
    "    has_WDPA_cat,\n",
    "    is_wood_fiber\n",
    "]\n",
    "\n",
    "TCL_query_args: List[SQLQueryArgs] = [\n",
    "    # TCL\n",
    "#     SQLQueryArgs(TCL, columns_of_interest, []),\n",
    "\n",
    "    # TCL + single intersections\n",
    "    *[\n",
    "        SQLQueryArgs(TCL, columns_of_interest, [intersection])\n",
    "        for intersection in TCL_intersections\n",
    "    ],\n",
    "\n",
    "    # TCL + multiple intersections\n",
    "    SQLQueryArgs(TCL, [columns_of_interest], [is_IFL_2k, has_WDPA_cat]),\n",
    "\n",
    "    # TCLF\n",
    "    SQLQueryArgs(TCLF, columns_of_interest, []),\n",
    "\n",
    "    # TCLF + single intersections\n",
    "    *[\n",
    "        SQLQueryArgs(TCLF, columns_of_interest, [intersection])\n",
    "        for intersection in TCLF_intersections\n",
    "    ],\n",
    "    SQLQueryArgs(TCLF, columns_of_interest, [is_IFL_2k]),\n",
    "    SQLQueryArgs(TCLF, columns_of_interest, [is_plantation]),\n",
    "\n",
    "    # TCLF + multiple intersections\n",
    "    *[\n",
    "        SQLQueryArgs(TCLF, columns_of_interest, [is_IFL_2k, intersection])\n",
    "        for intersection in TCLF_intersections\n",
    "    ],\n",
    "    *[\n",
    "        SQLQueryArgs(TCLF, columns_of_interest, [is_plantation, intersection])\n",
    "        for intersection in TCLF_intersections\n",
    "    ],\n",
    "]\n",
    "\n",
    "# TCL_query_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d86739a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from httpx import AsyncClient\n",
    "\n",
    "client = AsyncClient()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for filename, query_args in [\n",
    "#     (\"ghg_data.csv\", GHG_query_args),\n",
    "    (\"tcl_data.csv\", TCL_query_args)\n",
    "]:\n",
    "    dfs: List = []\n",
    "\n",
    "    with open(filename, 'w', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile, dialect=csv.excel)\n",
    "\n",
    "        csv_writer.writerow([\n",
    "            \"value\", *columns_of_interest, \"intersections\", versions[0], versions[1], \"percent_change\"\n",
    "        ])\n",
    "\n",
    "#         for combo in query_args[1:2]:  # Run the first query to test\n",
    "        for combo in query_args:\n",
    "\n",
    "            value_key = combo.base_column.strip('\"')\n",
    "\n",
    "            req_uri = compose_query_string(*combo, version=versions[0], api_uri=\"https://data-api.globalforestwatch.org\")\n",
    "            resp = await client.get(req_uri, follow_redirects=True, timeout=60)\n",
    "            if resp.status_code != 200:\n",
    "                print(resp.text)\n",
    "                continue\n",
    "            data_a = resp.json()[\"data\"]\n",
    "\n",
    "            df_a = pd.DataFrame(data_a)\n",
    "            df_a[\"value\"] = value_key\n",
    "            df_a[\"intersections\"] = f\"{' | '.join(combo.intersections)}\"\n",
    "\n",
    "            req_uri = compose_query_string(*combo, version=versions[1], api_uri=\"https://staging-data-api.globalforestwatch.org\")\n",
    "            resp = await client.get(req_uri, follow_redirects=True, timeout=60)\n",
    "            if resp.status_code != 200:\n",
    "                print(resp.text)\n",
    "                continue\n",
    "            data_b = resp.json()[\"data\"]\n",
    "\n",
    "            df_b = pd.DataFrame(data_b)\n",
    "            df_b[\"value\"] = value_key\n",
    "            df_b[\"intersections\"] = f\"{' | '.join(combo.intersections)}\"\n",
    "\n",
    "            df_a = df_a.rename(columns={value_key: versions[0]})\n",
    "            df_b = df_b.rename(columns={value_key: versions[1]})\n",
    "\n",
    "            combined_df = df_a.merge(df_b, on=[*combo.additional_columns, 'intersections', 'value'])\n",
    "            dfs.append(combined_df)\n",
    "\n",
    "    final_df = pd.concat(dfs)\n",
    "    final_df.to_csv(\n",
    "        filename, \n",
    "        index=False,\n",
    "        float_format = '%.3f',\n",
    "        columns=['value', 'intersections', *(query_args[0].additional_columns), versions[0], versions[1]]\n",
    "    )\n",
    "\n",
    "#     final_df = df_a.merge(df_b, on=['iso', 'umd_tree_cover_loss__year',\n",
    "#        'umd_tree_cover_density_2000__threshold', 'value'])\n",
    "#     final_df = pd.concat(dfs)\n",
    "#     final_df[\"diff\"] = (final_df[versions[0]] - final_df[versions[1]]).abs() / ((final_df[versions[0]] + final_df[versions[1]]) / 2) * 100\n",
    "#     final_df.to_csv(\n",
    "#         filename, \n",
    "#         index=False,\n",
    "#         float_format = '%.3f',\n",
    "#         columns=['value', 'intersections', *(query_args[0].additional_columns), versions[0], versions[1], 'diff']\n",
    "#     )\n",
    "\n",
    "        \n",
    "#             for a, b in zip(data_a, data_b):\n",
    "#                 row = [\n",
    "#                     value_key,\n",
    "#                     *[a[c] for c in combo.additional_columns],\n",
    "#                     \" | \".join(combo.intersections),\n",
    "#                     a[value_key],\n",
    "#                     b[value_key],\n",
    "#                     np.diff([a[value_key], b[value_key]])[0] / a[value_key] * 100\n",
    "#                 ]\n",
    "#                 csv_writer.writerow(row)\n",
    "\n",
    "print(\"All done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a392b90d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f1108d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
